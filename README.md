# Репозиторий содержит домашние задания по первой части курса Deep Learning School ФПМИ МФТИ

## 1. Основы машинного обучения

Разработан простой классификатор на основе метода K ближайших соседей для табличных данных. Использован Grid Search для настройки гиперпараметров с помощью библиотек pandas и sklearn.

## 2. Линейные модели и методы оптимизации

В этом разделе реализованы:
- Функция градиентного спуска для заданной функции \( f \).
- Генератор батчей.
- Класс для логистической регрессии с регуляризацией L1 и L2. 

Класс протестирован на сгенерированных данных и на датасете MNIST с применением кросс-валидации.

## 3. Решение ML-задачи и Kaggle

Проанализированы табличные данные с использованием pandas и matplotlib. Применены следующие методы:
- Линейная модель: создан Pipeline для предобработки данных (нормализация числовых и кодирование категориальных признаков) для предотвращения утечки данных при кросс-валидации. Логистическая регрессия обучена с помощью GridSearchCV из sklearn.
- Градиентный бустинг: обучен классификатор из catboost с использованием Grid Search.

Выполнен сабмит результатов на Kaggle.

## 4. Свёрточные и полносвязные нейросети

Разработан:
- Класс для логистической регрессии и цикл обучения на PyTorch.
- Тестирование различных функций активации на простой трёхслойной нейронной сети для MNIST.
- Сравнение различных ядер свёрток.
- Обучение модели LeNet на MNIST.

## 5. Классификация Симпсонов

В этом разделе реализованы:
- Класс датасета для загрузки изображений.
- Цикл обучения, чекпоинтинг, визуализация и базовая аугментация данных.
- Несколько архитектур свёрточных нейросетей, включая Max Pooling, Batch Normalization и Dropout.

Проведён поиск оптимальных гиперпараметров и архитектур для максимизации точности классификации. Выполнен сабмит результатов на Kaggle. Попробованы методы Fine-tuning с использованием предобученной модели ResNet18 и Karpathy Constant.

## 6. Сегментация изображений

В этом разделе:
- Реализована архитектура SegNet и функции потерь: Binary Cross-Entropy Loss, Dice Loss и Focal Loss, основанные на литературе и соответствующих статьях.
- Изучена и реализована функция потерь Correlation Maximized Structural Similarity Loss для семантической сегментации.
- Обучена модель SegNet с использованием указанных функций потерь.
- Реализована и обучена модель Unet с использованием BCE Loss.

Проведено сравнение качества сегментации по метрике IoU для различных обученных моделей.
